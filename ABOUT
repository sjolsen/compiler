Text in the scanner is handled through two interfaces: std::string and char_range, found in the text processing library. char_range is a wrapper around a pair of std::string iterators, defining a non-owning, non-modifying range along the underlying text. The range defined by a char_range is begin-inclusive, end-exclusive, in keeping with the standard library algorithm semantics.

The main interface to the tokenizing facilities is through the 'tokenize' function, found in the tokenizer library. This function takes as its argument a char_range describing the text to be tokenized, and returns a std::vector of 'token' -- a struct containing a type enum and a value field. Internally, this function operates by repeatedly dropping whitespace and comments from the working range and extracting the first viable token, until the working range is exhausted, or a syntax error is thrown. This syntax error consists of a descriptive error message, and an iterator to the current beginning of the working range, accessible via the 'where' function, analogous to std::exception's 'what'. The text processing library provides a class called 'file position' for converting an iterator to a <line, col> pair. It may be constructed from a char_range representing the underlying file, the iterator representing the position, and optionally a single-character line delimiter, defaulted to '\n'. The line represented by the file_position object thus created may be accessed through member 'first', and the column through member 'second'.

Token matching is performed by a set of token predicates, represented as the struct 'matcher'. These matchers implement operator (), which attempts to match a token from the beginning of the passed char_range. If there is no match candidate, an empty char_range is returned. If an syntax error is detected, an appropriate syntax_error is thrown. If a token is successfully identified, a char_range is returned describing that token. Each matcher also contains a function, 'token_constructor', which takes the range returned by the matcher's operator () and converts it into an appropriate internal, typed representation, throwing a syntax_error where appropriate. Token matching is performed in the following order: keyword, identifier, int_literal, char_literal, string_literal, symbol. Keywords are recognized by matching a strict subset of identifiers.

Available token types (as the enum class 'token_type') are 'identifier', 'keyword', 'int_literal', 'char_literal', 'string_literal', and 'symbol'. For tokens with types identifier, keyword, and string literal, the token's value is held in the member 'str'. int_literals are represented in that 'value' member, char_literals in 'cvalue', and symbols (or operators) in the member 'op'. Symbols are represented by appropriate values of the 'symbol' enum class. Both tokens and symbols may be converted to string representations through the to_string utility function. The former is represented as the string "<type, value>", while symbols are simply converted into the string from which they are constructed.